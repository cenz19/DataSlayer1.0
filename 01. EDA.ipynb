{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "  print(df[column].unique())\n",
    "  print(\" \")\n",
    "df.drop_duplicates(inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete rows that contain invalid values such as NaN, -1, missing, unspecified, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanData(df, col):\n",
    "        del_index=df[\n",
    "        (df[col]=='unspecified') | \n",
    "        (df[col]=='missing') | \n",
    "        (df[col]=='not-recorded') | \n",
    "        (df[col]=='not-available') |\n",
    "        (df[col]=='-1') |\n",
    "        (df[col]=='unknown') |\n",
    "        (df[col]=='na') |\n",
    "        (df[col]=='unestablished') | \n",
    "        (df[col]== np.nan) ].index\n",
    "        df.drop(del_index, inplace=True)\n",
    "        df.reset_index()    \n",
    "        return df\n",
    "col_clean=['Vehicle Class', 'Engine Size(L)', 'Cylinders', 'Transmission', 'Fuel Type']\n",
    "for col in col_clean:\n",
    "        df=CleanData(df, col)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "  print(df[column].unique())\n",
    "  print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to find unique units of fuel consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(num):\n",
    "    try:\n",
    "        float(num)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "list_temp=[]\n",
    "\n",
    "for record in df[\"Fuel Consumption City\"]:\n",
    "    try:\n",
    "        list_word=record.split(\" \", 1)\n",
    "        list_temp.append(list_word[1])\n",
    "    except:\n",
    "        continue\n",
    "for rec in set(list_temp):\n",
    "    if(is_float(rec)):\n",
    "        continue\n",
    "    else:\n",
    "        print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert every data unit into the same unit, L/100km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_l_per_hundred_km(df):\n",
    "    for col in [\"Fuel Consumption City\", \"Fuel Consumption Hwy\", \"Fuel Consumption Comb\"]:\n",
    "        list_temp=[]\n",
    "        for record in df[col]:\n",
    "            try:\n",
    "                list_word=record.split(\" \", 1)\n",
    "                if list_word[1]==\"mpg Imp.\":\n",
    "                    list_temp.append(282.481/float(list_word[0]))\n",
    "                elif list_word[1]==\"liters per 100 km\" or list_word[1]==\"L/100 km\" or list_word[1]==\"L/100km\":\n",
    "                    list_temp.append(float(list_word[0]))\n",
    "                elif list_word[1]==\"km/L\" or list_word[1]==\"km per L\":\n",
    "                    list_temp.append(100/float(list_word[0]))\n",
    "                elif list_word[1]==\"L/10km\":\n",
    "                    list_temp.append(float(list_word[0])*10)\n",
    "                elif list_word[1]==\"MPG (AS)\":\n",
    "                    list_temp.append(235.214/float(list_word[0]))\n",
    "            except:\n",
    "                list_temp.append(0)\n",
    "        df[col] = list_temp\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=convert_to_l_per_hundred_km(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zeros(df, column_name=\"\"):\n",
    "  df = df[df[column_name] != 0]\n",
    "  df.reset_index()\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete outliers and zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Outliers\n",
    "def remove_outliers(df, column_name=\"\"):\n",
    "  q1 = df[column_name].quantile(0.25)\n",
    "  q3 = df[column_name].quantile(0.75)\n",
    "\n",
    "  IQR = q3 - q1\n",
    "\n",
    "  lower_limit = q1 - 1.5 * IQR\n",
    "  upper_limit = q3 + 1.5 * IQR\n",
    "\n",
    "  df = df[(df[column_name] >= lower_limit) & (df[column_name] <= upper_limit)]\n",
    "  df.reset_index()\n",
    "  df=remove_zeros(df, column_name)\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_outliers(df,\"Fuel Consumption City\")\n",
    "df = remove_outliers(df,\"Fuel Consumption Hwy\")\n",
    "df = remove_outliers(df,\"Fuel Consumption Comb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Fuel Consumption City\", \"Fuel Consumption Hwy\", \"Fuel Consumption Comb\", \"CO2 Emissions(g/km)\"]].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace_value=[]\n",
    "# columns=['Make', 'Vehicle Class', 'Engine Size(L)', 'Cylinders', 'Transmission',\n",
    "#        'Fuel Type', 'Fuel Consumption City', 'Fuel Consumption Hwy',\n",
    "#        'Fuel Consumption Comb']\n",
    "# for col in columns:\n",
    "#     try:\n",
    "#         replace_value.append(np.mean(df[col]))\n",
    "#     except:\n",
    "#         print(col)\n",
    "#         replace_value.append(df[col].mode()[0])\n",
    "# print(replace_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv('train.csv')\n",
    "# for col in [\"Fuel Consumption City\", \"Fuel Consumption Hwy\", \"Fuel Consumption Comb\"]:\n",
    "#     list_temp=[]\n",
    "#     for record in df[col]:\n",
    "#         try:\n",
    "#             list_word=record.split(\" \", 1)\n",
    "#             list_temp.append(convert_to_l_per_hundred_km(list_word[0], list_word[1]))\n",
    "#         except:\n",
    "#             list_temp.append(0)\n",
    "#     df[col] = list_temp\n",
    "\n",
    "# def FillData(df, col, value_for_replace):\n",
    "#         wrong_index=df[\n",
    "#         (df[col]=='unspecified') | \n",
    "#         (df[col]=='missing') | \n",
    "#         (df[col]=='not-recorded') | \n",
    "#         (df[col]=='not-available') |\n",
    "#         (df[col]=='-1') |\n",
    "#         (df[col]=='unknown') |\n",
    "#         (df[col]=='na') |\n",
    "#         (df[col]=='unestablished') |\n",
    "#         (df[col]=='zero')].index\n",
    "#         df.loc[wrong_index, col]=value_for_replace\n",
    "#         df[col].fillna(value_for_replace, inplace=True)\n",
    "#         print(df[col].unique())\n",
    "#         return df\n",
    "# col_clean=['Make', 'Vehicle Class', 'Engine Size(L)', 'Cylinders', 'Transmission',\n",
    "#        'Fuel Type', 'Fuel Consumption City', 'Fuel Consumption Hwy',\n",
    "#        'Fuel Consumption Comb']\n",
    "# for i in range(len(col_clean)):\n",
    "#         df=FillData(df, col_clean[i], replace_value[i])\n",
    "# for column in df.columns:\n",
    "#   print(df[column].unique())\n",
    "#   print(\" \")\n",
    "# df.drop_duplicates(inplace=True)\n",
    "# len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_outliers(df,\"Fuel Consumption City\")\n",
    "df = remove_outliers(df,\"Fuel Consumption Hwy\")\n",
    "df = remove_outliers(df,\"Fuel Consumption Comb\")\n",
    "df = remove_outliers(df,\"CO2 Emissions(g/km)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to sort qualitative data based on their CO2 Consumption mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sorted_mean(df, column_name):\n",
    "  cols=df[column_name].unique()\n",
    "  avg=[np.average(df[\"CO2 Emissions(g/km)\"][df[column_name]==col]) for col in cols]\n",
    "  median=[np.median(df[\"CO2 Emissions(g/km)\"][df[column_name]==col]) for col in cols]\n",
    "  dict_col=dict(zip(cols, zip(avg, median)))\n",
    "  dict_col=sorted(dict_col.items(), key=lambda item: item[1])\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=(7,10))\n",
    "  bar_width = 0.4\n",
    "\n",
    "  bar1 = ax.barh(np.arange(len(cols)), [dict_col[:][i][1][0] for i in range(len(dict_col))], height=bar_width, color='yellow', alpha=0.5, label='Average')\n",
    "  bar2 = ax.barh(np.arange(len(cols)) + bar_width, [dict_col[:][i][1][1] for i in range(len(dict_col))], height=bar_width, color='orange', alpha=0.5, label='Median')\n",
    "\n",
    "  ax.set_yticks(np.arange(len(cols)) + bar_width / 2)\n",
    "  ax.set_yticklabels(dict_col)\n",
    "  ax.set_xlabel('CO2 Emissions(g/km)')\n",
    "  ax.set_ylabel(column_name)\n",
    "  ax.set_title('Visualization of CO2 emissions by ' + column_name)\n",
    "  ax.legend()\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "def generate_dict(df, column_name):\n",
    "  cols=df[column_name].unique()\n",
    "  avg=[np.average(df[\"CO2 Emissions(g/km)\"][df[column_name]==col]) for col in cols]\n",
    "  median=[np.median(df[\"CO2 Emissions(g/km)\"][df[column_name]==col]) for col in cols]\n",
    "  dict_col=dict(zip(cols, zip(avg, median)))\n",
    "  dict_col=sorted(dict_col.items(), key=lambda item: item[1])\n",
    "  return dict_col, avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sorted_mean(df, \"Make\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sorted_mean(df, \"Vehicle Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to add new column (Average CO2 Consumption of each unique label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddAvgColumn(df, column_name):\n",
    "    make_map={}\n",
    "    dict_col, avg=generate_dict(df, column_name)\n",
    "    for i in range(len(dict_col)):\n",
    "        make_map[dict_col[i][0]]=avg[i]\n",
    "    new_col=column_name+\"Avg\"\n",
    "    df[new_col]=df[column_name].map(make_map)\n",
    "    # df[new_col] = (df[new_col]-df[new_col].min())/df[new_col].max()\n",
    "    # df[new_col] = (df[new_col]-192.6185147143735)/271.26871156214463\n",
    "    \n",
    "    print(make_map)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=AddAvgColumn(df, \"Make\")\n",
    "df=AddAvgColumn(df, \"Vehicle Class\")\n",
    "df=AddAvgColumn(df, \"Transmission\")\n",
    "df=AddAvgColumn(df, \"Fuel Type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['MakeAvg'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sorted_mean(df, \"Transmission\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_box=['Fuel Consumption City', 'Fuel Consumption Hwy','Fuel Consumption Comb', \"CO2 Emissions(g/km)\"]\n",
    "plt.subplots(figsize=(10,10))\n",
    "plt.delaxes()\n",
    "i=1\n",
    "for col in col_box:\n",
    "    plt.subplot(2,2,i)\n",
    "    plt.boxplot(df[col])\n",
    "    plt.title(col)\n",
    "    i+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['X' 'E' 'Z' nan 'D' '-1' 'missing' 'unspecified' 'not-recorded' 'unknown', 'unestablished' 'na' 'not-available' 'N']\n",
    "# len(df[df[\"Fuel Type\"==\"unknown\"]])\n",
    "df[\"Fuel Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr=df[[\"Fuel Consumption City\", \"Fuel Consumption Hwy\", \"Fuel Consumption Comb\", \"CO2 Emissions(g/km)\", \"MakeAvg\",\"Make\",  \"Cylinders\", \"Engine Size(L)\"]].corr()\n",
    "corr=df[['Cylinders', 'Fuel Consumption City', 'Fuel Consumption Hwy',\n",
    "       'Fuel Consumption Comb', 'MakeAvg',\n",
    "       'Vehicle ClassAvg', 'TransmissionAvg', 'Fuel TypeAvg', \"CO2 Emissions(g/km)\"]].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Engine/Cylinders\"]=df[\"Engine Size(L)\"].astype(float)/df[\"Cylinders\"].astype(float)\n",
    "corr=df[[\"CO2 Emissions(g/km)\", \"Engine/Cylinders\"]].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALT 1\n",
    "# index_del=df[(df[\"Fuel Consumption City\"].astype(float)<100) | (df[\"Fuel Consumption Hwy\"].astype(float)<100) | (df[\"Fuel Consumption Comb\"].astype(float)<100)].index\n",
    "# df.drop(index_del, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALT 2\n",
    "df[\"Fuel Consumption City\"]=np.log10(df[\"Fuel Consumption City\"])\n",
    "df[\"Fuel Consumption Hwy\"]=np.log10(df[\"Fuel Consumption Hwy\"])\n",
    "df[\"Fuel Consumption Comb\"]=np.log10(df[\"Fuel Consumption Comb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df[\"Fuel Consumption City\"], df[\"CO2 Emissions(g/km)\"])\n",
    "plt.xlabel(\"Fuel Consumption City\")\n",
    "plt.ylabel(\"CO2 Emissions(g/km)\")  \n",
    "plt.show()\n",
    "\n",
    "plt.scatter(df[\"Fuel Consumption Hwy\"], df[\"CO2 Emissions(g/km)\"])\n",
    "plt.xlabel(\"Fuel Consumption Hwy\")\n",
    "plt.ylabel(\"CO2 Emissions(g/km)\")  \n",
    "plt.show()\n",
    "\n",
    "plt.scatter(df[\"Fuel Consumption Comb\"], df[\"CO2 Emissions(g/km)\"])\n",
    "plt.xlabel(\"Fuel Consumption Comb\")\n",
    "plt.ylabel(\"CO2 Emissions(g/km)\")  \n",
    "plt.show()\n",
    "\n",
    "plt.scatter(df[\"Cylinders\"], df[\"CO2 Emissions(g/km)\"])\n",
    "plt.xlabel(\"Cylinders\")\n",
    "plt.ylabel(\"CO2 Emissions(g/km)\")  \n",
    "plt.show()\n",
    "# corr=df[[\"Fuel Consumption City\", \"Fuel Consumption Hwy\", \"Fuel Consumption Comb\", \"CO2 Emissions(g/km)\", \"Make\", \"Cylinders\", \"Engine Size(L)\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del_index=df[(df[\"Fuel Consumption City\"]>15000) | (df[\"Fuel Consumption Hwy\"]>15000) | (df[\"Fuel Consumption Comb\"]>800)].index\n",
    "del_index=df[(df[\"Fuel Consumption City\"]>15000000)].index\n",
    "df.drop(del_index, inplace=True)\n",
    "df.reset_index()\n",
    "plt.scatter(df[\"Fuel Consumption City\"], df[\"Fuel Consumption Hwy\"])\n",
    "plt.xlabel(\"Fuel Consumption City\")\n",
    "plt.ylabel(\"Fuel Consumption Hwy\")  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df[\"Engine Size(L)\"], df[\"CO2 Emissions(g/km)\"])\n",
    "plt.xlabel(\"Fuel Consumption City\")\n",
    "plt.ylabel(\"CO2 Emissions(g/km)\")  \n",
    "plt.show()\n",
    "\n",
    "plt.scatter(df[\"Cylinders\"], df[\"CO2 Emissions(g/km)\"])\n",
    "plt.xlabel(\"Fuel Consumption Hwy\")\n",
    "plt.ylabel(\"CO2 Emissions(g/km)\")  \n",
    "plt.show()\n",
    "# corr=df[[\"Fuel Consumption City\", \"Fuel Consumption Hwy\", \"Fuel Consumption Comb\", \"CO2 Emissions(g/km)\", \"Make\", \"Cylinders\", \"Engine Size(L)\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df.to_csv(\"preprocessing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"preprocessing.csv\", index_col=0)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841/841 [==============================] - 7s 9ms/step - loss: 1004.4962 - root_mean_squared_error: 31.6938 - val_loss: 979.2927 - val_root_mean_squared_error: 31.2937\n",
      "Epoch 18/50\n",
      "841/841 [==============================] - 7s 8ms/step - loss: 1000.6661 - root_mean_squared_error: 31.6333 - val_loss: 975.5688 - val_root_mean_squared_error: 31.2341\n",
      "Epoch 19/50\n",
      "841/841 [==============================] - 6s 7ms/step - loss: 996.8600 - root_mean_squared_error: 31.5731 - val_loss: 971.8648 - val_root_mean_squared_error: 31.1747\n",
      "Epoch 20/50\n",
      "841/841 [==============================] - 8s 9ms/step - loss: 993.0740 - root_mean_squared_error: 31.5131 - val_loss: 968.1804 - val_root_mean_squared_error: 31.1156\n",
      "Epoch 21/50\n",
      "841/841 [==============================] - 6s 7ms/step - loss: 989.3071 - root_mean_squared_error: 31.4533 - val_loss: 964.5140 - val_root_mean_squared_error: 31.0566\n",
      "Epoch 22/50\n",
      "841/841 [==============================] - 7s 9ms/step - loss: 985.5591 - root_mean_squared_error: 31.3936 - val_loss: 960.8655 - val_root_mean_squared_error: 30.9978\n",
      "Epoch 23/50\n",
      "841/841 [==============================] - 7s 8ms/step - loss: 981.8287 - root_mean_squared_error: 31.3341 - val_loss: 957.2326 - val_root_mean_squared_error: 30.9392\n",
      "Epoch 24/50\n",
      "841/841 [==============================] - 7s 8ms/step - loss: 978.1140 - root_mean_squared_error: 31.2748 - val_loss: 953.6156 - val_root_mean_squared_error: 30.8807\n",
      "Epoch 25/50\n",
      "841/841 [==============================] - 9s 10ms/step - loss: 974.4148 - root_mean_squared_error: 31.2156 - val_loss: 950.0126 - val_root_mean_squared_error: 30.8223\n",
      "Epoch 26/50\n",
      "841/841 [==============================] - 6s 7ms/step - loss: 970.7294 - root_mean_squared_error: 31.1565 - val_loss: 946.4238 - val_root_mean_squared_error: 30.7640\n",
      "Epoch 27/50\n",
      "841/841 [==============================] - 7s 9ms/step - loss: 967.0573 - root_mean_squared_error: 31.0975 - val_loss: 942.8489 - val_root_mean_squared_error: 30.7058\n",
      "Epoch 28/50\n",
      "841/841 [==============================] - 8s 10ms/step - loss: 963.3974 - root_mean_squared_error: 31.0386 - val_loss: 939.2855 - val_root_mean_squared_error: 30.6478\n",
      "Epoch 29/50\n",
      "841/841 [==============================] - 7s 8ms/step - loss: 959.7510 - root_mean_squared_error: 30.9798 - val_loss: 935.7344 - val_root_mean_squared_error: 30.5898\n",
      "Epoch 30/50\n",
      "841/841 [==============================] - 5s 6ms/step - loss: 956.1137 - root_mean_squared_error: 30.9211 - val_loss: 932.1945 - val_root_mean_squared_error: 30.5319\n",
      "Epoch 31/50\n",
      "841/841 [==============================] - 6s 7ms/step - loss: 952.4879 - root_mean_squared_error: 30.8624 - val_loss: 928.6653 - val_root_mean_squared_error: 30.4740\n",
      "Epoch 32/50\n",
      "841/841 [==============================] - 7s 9ms/step - loss: 948.8722 - root_mean_squared_error: 30.8038 - val_loss: 925.1472 - val_root_mean_squared_error: 30.4162\n",
      "Epoch 33/50\n",
      "841/841 [==============================] - 7s 8ms/step - loss: 945.2667 - root_mean_squared_error: 30.7452 - val_loss: 921.6389 - val_root_mean_squared_error: 30.3585\n",
      "Epoch 34/50\n",
      "841/841 [==============================] - 5s 6ms/step - loss: 941.6686 - root_mean_squared_error: 30.6866 - val_loss: 918.1399 - val_root_mean_squared_error: 30.3008\n",
      "Epoch 35/50\n",
      "841/841 [==============================] - 7s 9ms/step - loss: 938.0800 - root_mean_squared_error: 30.6281 - val_loss: 914.6511 - val_root_mean_squared_error: 30.2432\n",
      "Epoch 36/50\n",
      "185/841 [=====>........................] - ETA: 3s - loss: 964.6238 - root_mean_squared_error: 31.0584"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[667], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# model.compile(loss=\"mae\", optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=tf.keras.metrics.RootMeanSquaredError())\u001b[39;00m\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m3e-4\u001b[39m), metrics\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mRootMeanSquaredError())\n\u001b[0;32m---> 19\u001b[0m history\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCO2 Emissions(g/km)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(6, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(6, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"linear\")\n",
    "])\n",
    "# col_train=['Make', 'Vehicle Class', 'Engine Size(L)', 'Cylinders', 'Transmission',\n",
    "#        'Fuel Type', 'Fuel Consumption City', 'Fuel Consumption Hwy',\n",
    "#        'Fuel Consumption Comb', 'CO2 Emissions(g/km)', 'MakeAvg',\n",
    "#        'Vehicle ClassAvg', 'TransmissionAvg', 'Fuel TypeAvg']\n",
    "col_train=['Cylinders',\n",
    "       'Fuel Consumption City', 'Fuel Consumption Hwy',\n",
    "       'Fuel Consumption Comb']\n",
    "\n",
    "# model.compile(loss=\"mae\", optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=tf.keras.metrics.RootMeanSquaredError())\n",
    "model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(3e-4), metrics=tf.keras.metrics.RootMeanSquaredError())\n",
    "\n",
    "history=model.fit(df_train[col_train], df_train[\"CO2 Emissions(g/km)\"], epochs=50, validation_split=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.sqrt(history.history['loss'])\n",
    "val_loss = np.sqrt(history.history['val_loss'])\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_test=convert_to_l_per_hundred_km(df_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_test.columns:\n",
    "    nan_index=df_test[(df_test[col]=='unspecified') | \n",
    "        (df_test[col]=='missing') | \n",
    "        (df_test[col]=='not-recorded') | \n",
    "        (df_test[col]=='not-available') |\n",
    "        (df_test[col]=='-1') |\n",
    "        (df_test[col]=='unknown') |\n",
    "        (df_test[col]=='na') |\n",
    "        (df_test[col]=='unestablished') | \n",
    "        (df_test[col]=='zero') | \n",
    "        (df_test[col]==-9999) | \n",
    "        (df_test[col]==-1) | \n",
    "        (df_test[col]== 0) | \n",
    "        (df_test[col]== np.nan) ].index\n",
    "    df_test.loc[nan_index,col] = np.nan\n",
    "df_checknull=df_test[[\"Id\", 'Vehicle Class', 'Engine Size(L)', 'Cylinders', 'Transmission', 'Fuel Type', 'Fuel Consumption City', 'Fuel Consumption Hwy', 'Fuel Consumption Comb']].isnull()\n",
    "df_checknull.drop_duplicates(inplace=True)\n",
    "print(len(df_checknull))\n",
    "# print(df_checknull.drop_duplicates())\n",
    "df_checknull.to_excel(\"Combination NULL.xlsx\")\n",
    "nan_counts = df_test[[\"Id\", 'Vehicle Class', 'Engine Size(L)', 'Cylinders', 'Transmission', 'Fuel Type']].isna().sum(axis=1)\n",
    "\n",
    "# Filter rows with more than 3 NaN values\n",
    "# result = df[nan_counts > 3]\n",
    "# print(result)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(np.expand_dims(np.asarray(df_test[col_train]), -1).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output=pd.DataFrame(prediction)\n",
    "df_output.to_excel(\"output.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
